{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to output the necessary fields for the CALP constraint for CMIP5.  This includes...\n",
    "\n",
    "- Interannual correlation between DJF Nino3.4 and California precipitation for 1948-2014 or historical and RCP8.5 concatenated (after detrending)\n",
    "- Interannual correlation between DJF Nino3.4 and California precipitation for 2006-2099 of RCP8.5 (after detrending)\n",
    "- DJF trend in precipitation from 2006-2099 in RCP8.5.\n",
    "\n",
    "Output is put to ecpaper2020/DATASORT/CALP/DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import xesmf as xe\n",
    "from numpy import nan\n",
    "import sys\n",
    "import warnings\n",
    "from scipy import signal\n",
    "\n",
    "from ecpaper_utils import readdata_utils as read\n",
    "from ecpaper_utils import calendar_utils as cal\n",
    "from ecpaper_utils import shapefile_utils as shp\n",
    "from ecpaper_utils import averaging_utils as avg\n",
    "from ecpaper_utils import linfit_utils as linfit\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO\n",
    "\n",
    "importlib.reload(read)\n",
    "importlib.reload(cal)\n",
    "importlib.reload(shp)\n",
    "importlib.reload(avg)\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set paths for CMIP5 models (historical and RCP8.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "histpath=\"/project/cmip5/historical/Amon/\"\n",
    "rcp85path=\"/project/cmip5/rcp85/Amon/\"\n",
    "pathout=\"/project/cas/islas/python/ecpaper2020/DATASORT/CALP/DATA/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on the models is being provided in cmip5csvinfo.csv.  This contains information on the models, number of members and whether there's any special order for the member numbers i.e., if they don't simply go from 1 to N.  Read in this info and set up the dates for each period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmip5models = pd.read_csv(\"../cmip5csvinfo.csv\")\n",
    "\n",
    "ybegp=1948 ; monbegp=1 ; yendp=2014 ; monendp=12 # dates for past period\n",
    "ybegf=2006 ; monbegf=1 ; yendf=2099 ; monendf=12 # dates for future period\n",
    "\n",
    "# total number of months (used for checking)\n",
    "nmonthsp = (yendp-ybegp-1)*12 + (12-monbegp+1) + monendp\n",
    "nmonthsf = (yendf-ybegf-1)*12 + (12-monbegf+1) + monendf\n",
    "\n",
    "# set up date names\n",
    "datebegp=str(ybegp)+\"-\"+str(monbegp).zfill(2)\n",
    "dateendp=str(yendp)+\"-\"+str(monendp).zfill(2)\n",
    "datebegf=str(ybegf)+\"-\"+str(monbegf).zfill(2)\n",
    "dateendf=str(yendf)+\"-\"+str(monendf).zfill(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up shapefile for USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#USA\n",
    "shpdir = \"/project/cas/islas/python/ecpaper2020/shapefiles/USA/\"\n",
    "shpurl = \"https://biogeo.ucdavis.edu/data/gadm3.6/shp/gadm36_USA_shp.zip\"\n",
    "with urlopen(shpurl) as ziploc:\n",
    "    with ZipFile(BytesIO(ziploc.read())) as zfile:\n",
    "        zfile.extractall(shpdir)\n",
    "shpfile_USA = shpdir+\"gadm36_USA_1.shp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing past for ACCESS1-0 r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "masking California\n",
      "Processing past for ACCESS1-3 r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for bcc-csm1-1 r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for bcc-csm1-1-m r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for BNU-ESM r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for CanESM2 r1i1p1...\n",
      "Processing past for CanESM2 r2i1p1...\n",
      "Processing past for CanESM2 r3i1p1...\n",
      "Processing past for CanESM2 r4i1p1...\n",
      "Processing past for CanESM2 r5i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing Future for r3i1p1...\n",
      "Processing Future for r4i1p1...\n",
      "Processing Future for r5i1p1...\n",
      "Processing past for CCSM4 r1i1p1...\n",
      "Processing past for CCSM4 r2i1p1...\n",
      "Processing past for CCSM4 r3i1p1...\n",
      "Processing past for CCSM4 r4i1p1...\n",
      "Processing past for CCSM4 r5i1p1...\n",
      "Processing past for CCSM4 r6i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing Future for r3i1p1...\n",
      "Processing Future for r4i1p1...\n",
      "Processing Future for r5i1p1...\n",
      "Processing Future for r6i1p1...\n",
      "Processing past for CESM1-BGC r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for CESM1-CAM5 r1i1p1...\n",
      "Processing past for CESM1-CAM5 r2i1p1...\n",
      "Processing past for CESM1-CAM5 r3i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing Future for r3i1p1...\n",
      "Processing past for CESM1-WACCM r2i1p1...\n",
      "using a different start date for WACCM\n",
      "Processing Future for r2i1p1...\n",
      "Processing past for CMCC-CM r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for CMCC-CMS r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for CNRM-CM5 r1i1p1...\n",
      "Processing past for CNRM-CM5 r2i1p1...\n",
      "Processing past for CNRM-CM5 r4i1p1...\n",
      "Processing past for CNRM-CM5 r6i1p1...\n",
      "Processing past for CNRM-CM5 r10i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing Future for r4i1p1...\n",
      "Processing Future for r6i1p1...\n",
      "Processing Future for r10i1p1...\n",
      "Processing past for CSIRO-Mk3-6-0 r1i1p1...\n",
      "Processing past for CSIRO-Mk3-6-0 r2i1p1...\n",
      "Processing past for CSIRO-Mk3-6-0 r3i1p1...\n",
      "Processing past for CSIRO-Mk3-6-0 r4i1p1...\n",
      "Processing past for CSIRO-Mk3-6-0 r5i1p1...\n",
      "Processing past for CSIRO-Mk3-6-0 r6i1p1...\n",
      "Processing past for CSIRO-Mk3-6-0 r7i1p1...\n",
      "Processing past for CSIRO-Mk3-6-0 r8i1p1...\n",
      "Processing past for CSIRO-Mk3-6-0 r9i1p1...\n",
      "Processing past for CSIRO-Mk3-6-0 r10i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing Future for r3i1p1...\n",
      "Processing Future for r4i1p1...\n",
      "Processing Future for r5i1p1...\n",
      "Processing Future for r6i1p1...\n",
      "Processing Future for r7i1p1...\n",
      "Processing Future for r8i1p1...\n",
      "Processing Future for r9i1p1...\n",
      "Processing Future for r10i1p1...\n",
      "Processing past for EC-EARTH r8i1p1...\n",
      "Processing Future for r8i1p1...\n",
      "Processing past for FGOALS-g2 r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for FIO-ESM r1i1p1...\n",
      "Processing past for FIO-ESM r2i1p1...\n",
      "Processing past for FIO-ESM r3i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing Future for r3i1p1...\n",
      "Processing past for GFDL-CM3 r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for GFDL-ESM2G r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for GFDL-ESM2M r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for GISS-E2-H r1i1p1...\n",
      "Processing past for GISS-E2-H r2i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing past for GISS-E2-R r1i1p1...\n",
      "Processing past for GISS-E2-R r2i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing past for HadGEM2-AO r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for HadGEM2-CC r1i1p1...\n",
      "using a different start date for HadGEM2-CC\n",
      "Processing past for HadGEM2-CC r2i1p1...\n",
      "using a different start date for HadGEM2-CC\n",
      "Processing past for HadGEM2-CC r3i1p1...\n",
      "using a different start date for HadGEM2-CC\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing Future for r3i1p1...\n",
      "Processing past for HadGEM2-ES r1i1p1...\n",
      "Processing past for HadGEM2-ES r2i1p1...\n",
      "Processing past for HadGEM2-ES r3i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing Future for r3i1p1...\n",
      "Processing past for inmcm4 r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for IPSL-CM5A-LR r1i1p1...\n",
      "Processing past for IPSL-CM5A-LR r2i1p1...\n",
      "Processing past for IPSL-CM5A-LR r3i1p1...\n",
      "Processing past for IPSL-CM5A-LR r4i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing Future for r3i1p1...\n",
      "Processing Future for r4i1p1...\n",
      "Processing past for IPSL-CM5A-MR r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for IPSL-CM5B-LR r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for MIROC5 r1i1p1...\n",
      "Processing past for MIROC5 r2i1p1...\n",
      "Processing past for MIROC5 r3i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing Future for r3i1p1...\n",
      "Processing past for MIROC-ESM r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for MIROC-ESM-CHEM r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for MPI-ESM-LR r1i1p1...\n",
      "Processing past for MPI-ESM-LR r2i1p1...\n",
      "Processing past for MPI-ESM-LR r3i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing Future for r2i1p1...\n",
      "Processing Future for r3i1p1...\n",
      "Processing past for MPI-ESM-MR r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for MRI-CGCM3 r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for NorESM1-M r1i1p1...\n",
      "Processing Future for r1i1p1...\n",
      "Processing past for NorESM1-ME r1i1p1...\n",
      "Processing Future for r1i1p1...\n"
     ]
    }
   ],
   "source": [
    "models = cmip5models[\"Model\"]\n",
    "nmodels=models.size\n",
    "\n",
    "# define 1 deg greid\n",
    "grid_out = xr.Dataset({'lat': (['lat'], np.arange(-90,91,1.0)), 'lon': (['lon'], np.arange(0,360,1.0))})\n",
    "nlon = grid_out[\"lon\"].size ; nlat=grid_out[\"lat\"].size\n",
    "\n",
    "# define multi model arrays\n",
    "prtrend_2006_2099 = xr.DataArray(np.zeros([nmodels, nlat, nlon]), coords=[models, grid_out[\"lat\"], grid_out[\"lon\"]],\n",
    "                                dims=['Model', 'lat', 'lon'], name='prtrend_2006_2099')\n",
    "cor_nino_calp_p = xr.DataArray(np.zeros([nmodels]), coords=[models], dims=['Model'], name='cor_nino_calp_p')\n",
    "cor_nino_calp_f = xr.DataArray(np.zeros([nmodels]), coords=[models], dims=['Model'], name='cor_nino_calp_f')\n",
    "calptrend_em = xr.DataArray(np.zeros([nmodels]), coords=[models], dims=['Model'], name='calptrend')\n",
    "\n",
    "# loop over models\n",
    "for index, modname in models.iteritems():\n",
    "    \n",
    "    # initialize boolean for reusing weights\n",
    "    wgtfile=\"/project/cas/islas/python/ecpaper2020/DATASORT/CALP/tmp/wgt.nc\"\n",
    "    reusewgt=False\n",
    "    \n",
    "    # ---the past period----\n",
    "    nmems=cmip5models.loc[index, \"Nmempast\"]\n",
    "    for imem in range(1, nmems+1, 1): # loop over members\n",
    "        memstr=\"r\"+str(imem)+\"i1p1\"\n",
    "        \n",
    "        # check for a special order\n",
    "        changeorder = cmip5models.loc[index, \"specialorderpast\"]\n",
    "        if (type(changeorder)==str):\n",
    "            changeordernp = np.array(changeorder.split(\",\"))\n",
    "            memstr=\"r\"+str(changeordernp[imem-1])+\"i1p1\"\n",
    "            \n",
    "        print(\"Processing past for \"+modname+\" \"+memstr+\"...\")\n",
    "        histdir=histpath+\"pr/\"+modname+\"/\"+memstr+\"/\"\n",
    "        rcp85dir=rcp85path+\"pr/\"+modname+\"/\"+memstr+\"/\"\n",
    "        prhist = read.read_sfc(histdir+\"/*.nc\", datebegp, \"2005-12\")\n",
    "        prrcp = read.read_sfc(rcp85dir+\"/*.nc\", \"2006-01\", dateendp)\n",
    "        pr = xr.concat([prhist, prrcp], dim=\"time\", join=\"override\")\n",
    "        \n",
    "        histdir=histpath+\"ts/\"+modname+\"/\"+memstr+\"/\"\n",
    "        rcp85dir=rcp85path+\"ts/\"+modname+\"/\"+memstr+\"/\"\n",
    "        tshist = read.read_sfc(histdir+\"/*.nc\", datebegp, \"2005-12\")\n",
    "        tsrcp = read.read_sfc(rcp85dir+\"/*.nc\", \"2006-01\", dateendp)\n",
    "        ts = xr.concat([tshist, tsrcp], dim=\"time\", join=\"override\")\n",
    "\n",
    "        # since WACCM starts in 1955 use 1950-2021 for the historical period\n",
    "        if (modname == \"CESM1-WACCM\"):\n",
    "            print(\"using a different start date for WACCM\")\n",
    "            histdir=histpath+\"pr/\"+modname+\"/\"+memstr+\"/\"\n",
    "            rcp85dir=rcp85path+\"pr/\"+modname+\"/\"+memstr+\"/\"\n",
    "            prhist = read.read_sfc(histdir+\"/*.nc\", \"1955-01\", \"2005-12\")\n",
    "            prrcp = read.read_sfc(rcp85dir+\"/*.nc\", \"2006-01\", \"2021-12\")\n",
    "            pr = xr.concat([prhist, prrcp], dim=\"time\", join=\"override\")\n",
    "        \n",
    "            histdir=histpath+\"ts/\"+modname+\"/\"+memstr+\"/\"\n",
    "            rcp85dir=rcp85path+\"ts/\"+modname+\"/\"+memstr+\"/\"\n",
    "            tshist = read.read_sfc(histdir+\"/*.nc\", \"1955-01\", \"2005-12\")\n",
    "            tsrcp = read.read_sfc(rcp85dir+\"/*.nc\", \"2006-01\", \"2021-12\")\n",
    "            ts = xr.concat([tshist, tsrcp], dim=\"time\", join=\"override\")\n",
    "            \n",
    "        # since HadGEM2-CC starts in 1960 use 1960-2026 for the historical period\n",
    "        \n",
    "        if (modname == \"HadGEM2-CC\"):\n",
    "            print(\"using a different start date for HadGEM2-CC\")\n",
    "            histdir=histpath+\"pr/\"+modname+\"/\"+memstr+\"/\"\n",
    "            rcp85dir=rcp85path+\"pr/\"+modname+\"/\"+memstr+\"/\"\n",
    "            prhist = read.read_sfc(histdir+\"/*.nc\", \"1960-01\", \"2005-12\")\n",
    "            prrcp = read.read_sfc(rcp85dir+\"/*.nc\", \"2006-01\", \"2026-12\")\n",
    "            pr = xr.concat([prhist, prrcp], dim=\"time\", join=\"override\")\n",
    "        \n",
    "            histdir=histpath+\"ts/\"+modname+\"/\"+memstr+\"/\"\n",
    "            rcp85dir=rcp85path+\"ts/\"+modname+\"/\"+memstr+\"/\"\n",
    "            tshist = read.read_sfc(histdir+\"/*.nc\", \"1960-01\", \"2005-12\")\n",
    "            tsrcp = read.read_sfc(rcp85dir+\"/*.nc\", \"2006-01\", \"2026-12\")\n",
    "            ts = xr.concat([tshist, tsrcp], dim=\"time\", join=\"override\")                \n",
    "        \n",
    "        # check array length.  If this fails, try ending historical in 2005-11\n",
    "        # and beginning rcp in 2005-12 to fix Hadley center\n",
    "        if ((pr.time.size != nmonthsp) or (ts.time.size != nmonthsp)):\n",
    "            histdir=histpath+\"pr/\"+modname+\"/\"+memstr+\"/\"\n",
    "            rcp85dir=rcp85path+\"pr/\"+modname+\"/\"+memstr+\"/\"\n",
    "            prhist = read.read_sfc(histdir+\"/*.nc\", datebegp, \"2005-11\")\n",
    "            prrcp = read.read_sfc(rcp85dir+\"/*.nc\", \"2005-12\", dateendp)\n",
    "            pr = xr.concat([prhist, prrcp], dim=\"time\", join=\"override\")\n",
    "        \n",
    "            histdir=histpath+\"ts/\"+modname+\"/\"+memstr+\"/\"\n",
    "            rcp85dir=rcp85path+\"ts/\"+modname+\"/\"+memstr+\"/\"\n",
    "            tshist = read.read_sfc(histdir+\"/*.nc\", datebegp, \"2005-11\")\n",
    "            tsrcp = read.read_sfc(rcp85dir+\"/*.nc\", \"2005-12\", dateendp)\n",
    "            ts = xr.concat([tshist, tsrcp], dim=\"time\", join=\"override\")\n",
    "        \n",
    "        \n",
    "        # check again\n",
    "        if ((pr.time.size != nmonthsp) or (ts.time.size != nmonthsp)):\n",
    "            print(\"something's wrong.  nmonthsp=\"+str(nmonthsp)+\" but got \"+str(pr.time.size)+\"/\"+str(ts.time.size)+\" for pr/ts\")\n",
    "            sys.exit(\"failed at past for \"+modname+\" \"+memstr)\n",
    "        \n",
    "        \n",
    "        # convert to mm/day\n",
    "        pr['pr']=pr['pr']*86400.\n",
    "\n",
    "        prdjf = cal.season_ts(pr, 'pr', 'DJF')\n",
    "        tsdjf = cal.season_ts(ts, 'ts', 'DJF')\n",
    "        \n",
    "        if (imem == 1):\n",
    "            prgather_p = xr.DataArray(np.zeros([nmems, prdjf.time.size, prdjf.lat.size, prdjf.lon.size]), \n",
    "                                       coords=[np.arange(0,nmems), prdjf['time'], prdjf['lat'], prdjf['lon']], \n",
    "                                       dims=['Member','time','lat','lon'], name='pr')\n",
    "            tsgather_p = xr.DataArray(np.zeros([nmems, tsdjf.time.size, tsdjf.lat.size, tsdjf.lon.size]), \n",
    "                                       coords=[np.arange(0,nmems), tsdjf['time'], tsdjf['lat'], tsdjf['lon']], \n",
    "                                       dims=['Member','time','lat','lon'], name='pr')\n",
    "        \n",
    "        prgather_p[imem-1,:,:,:]=np.array(prdjf)\n",
    "        tsgather_p[imem-1,:,:,:]=np.array(tsdjf)\n",
    "        \n",
    "    # ----- future period ------\n",
    "    nmems = cmip5models.loc[index, \"Nmemfuture\"]\n",
    "    for imem in range(1, nmems+1, 1): # loop over future members\n",
    "        memstr=\"r\"+str(imem)+\"i1p1\"\n",
    "        \n",
    "        changeorder = cmip5models.loc[index, \"specialorderfuture\"]\n",
    "        if (type(changeorder)==str):\n",
    "            changeordernp = np.array(changeorder.split(\",\"))\n",
    "            memstr=\"r\"+str(changeordernp[imem-1])+\"i1p1\"\n",
    "        \n",
    "        print(\"Processing Future for \"+memstr+\"...\")\n",
    "        rcp85dir=rcp85path+\"pr/\"+modname+\"/\"+memstr+\"/\"\n",
    "        pr = read.read_sfc(rcp85dir+\"/*.nc\", datebegf, dateendf)\n",
    "        rcp85dir=rcp85path+\"ts/\"+modname+\"/\"+memstr+\"/\"\n",
    "        ts = read.read_sfc(rcp85dir+\"/*.nc\", datebegf, dateendf)\n",
    "        \n",
    "        # check array sizes\n",
    "        if ((pr.time.size != nmonthsf) or (ts.time.size != nmonthsf)):\n",
    "            print(\"Something's wrong. nmonthsf=\"+str(nmonthsf)+\" but got \"+str(ts.time.size)+\"/\"+str(ts.time.size)+\" for pr/ts\")\n",
    "            sys.exit(\"failed at future for \"+modname+\" \"+memstr)\n",
    "        \n",
    "        # convert to mm/day\n",
    "        pr['pr'] = pr['pr']*86400.\n",
    "        \n",
    "        prdjf = cal.season_ts(pr, 'pr', 'DJF')\n",
    "        tsdjf = cal.season_ts(ts, 'ts', 'DJF')\n",
    "        \n",
    "        if (imem == 1):\n",
    "            prgather_f = xr.DataArray(np.zeros([nmems, prdjf.time.size, prdjf.lat.size, prdjf.lon.size]), \n",
    "                                       coords=[np.arange(0,nmems), prdjf['time'], prdjf['lat'], prdjf['lon']], \n",
    "                                       dims=['Member','time','lat','lon'], name='pr')\n",
    "            tsgather_f = xr.DataArray(np.zeros([nmems, tsdjf.time.size, tsdjf.lat.size, tsdjf.lon.size]), \n",
    "                                       coords=[np.arange(0,nmems), tsdjf['time'], tsdjf['lat'], tsdjf['lon']], \n",
    "                                       dims=['Member','time','lat','lon'], name='pr')\n",
    "        \n",
    "        prgather_f[imem-1,:,:,:]=np.array(prdjf)\n",
    "        tsgather_f[imem-1,:,:,:]=np.array(tsdjf)\n",
    "        \n",
    "        \n",
    "    # interpolate to 1 degree grid and calculate area averages\n",
    "    regridder = xe.Regridder(prgather_p, grid_out, 'bilinear', periodic=True, reuse_weights=reusewgt, filename=wgtfile)\n",
    "    prgather_p_interp = regridder(prgather_p)\n",
    "    reusewgt=True\n",
    "    regridder = xe.Regridder(prgather_f, grid_out, 'bilinear', periodic=True, reuse_weights=reusewgt, filename=wgtfile)\n",
    "    prgather_f_interp = regridder(prgather_f)\n",
    "    regridder = xe.Regridder(tsgather_p, grid_out, 'bilinear', periodic=True, reuse_weights=reusewgt, filename=wgtfile)\n",
    "    tsgather_p_interp = regridder(tsgather_p)\n",
    "    regridder = xe.Regridder(tsgather_f, grid_out, 'bilinear', periodic=True, reuse_weights=reusewgt, filename=wgtfile)\n",
    "    tsgather_f_interp = regridder(tsgather_f)\n",
    "    \n",
    "    prgather_f_em = prgather_f_interp.mean(\"Member\")\n",
    "    \n",
    "    prgather_p_detrend = xr.DataArray(signal.detrend(prgather_p_interp, axis=1), coords=prgather_p_interp.coords)\n",
    "    prgather_f_detrend = xr.DataArray(signal.detrend(prgather_f_interp, axis=1), coords=prgather_f_interp.coords)\n",
    "    tsgather_p_detrend = xr.DataArray(signal.detrend(tsgather_p_interp, axis=1), coords=tsgather_p_interp.coords)\n",
    "    tsgather_f_detrend = xr.DataArray(signal.detrend(tsgather_f_interp, axis=1), coords=tsgather_f_interp.coords)   \n",
    "    \n",
    "    nino34_p = avg.cosweightlonlat(tsgather_p_detrend, 190, 240, -5, 5)\n",
    "    nino34_f = avg.cosweightlonlat(tsgather_f_detrend, 190, 240, -5, 5)\n",
    "    \n",
    "    if (index == 0) and (imem == 1): # only need to make the mask for 1 deg  once\n",
    "        mask = shp.maskgen(shpfile_USA, prgather_p_detrend, ['California'])\n",
    "    \n",
    "    prgather_p_mskd = xr.DataArray(np.array(prgather_p_detrend)*np.array(mask), coords=prgather_p_detrend.coords)\n",
    "    prgather_f_mskd = xr.DataArray(np.array(prgather_f_detrend)*np.array(mask), coords=prgather_f_detrend.coords)\n",
    "    prcal_p=avg.cosweightlonlat(prgather_p_mskd, 0, 360, -90, 90)\n",
    "    prcal_p = prcal_p.rename('pr')\n",
    "    prcal_f=avg.cosweightlonlat(prgather_f_mskd, 0, 360, -90, 90)\n",
    "    prcal_f = prcal_f.rename('pr')\n",
    "    \n",
    "    \n",
    "    cor_nino_calp_p[index] = xr.corr(prcal_p, nino34_p)\n",
    "    cor_nino_calp_f[index] = xr.corr(prcal_f, nino34_f)\n",
    "\n",
    "    # convert time axis to year for detrending\n",
    "    year = prgather_f_em['time'].dt.year\n",
    "    prgather_f_em['time'] = year\n",
    "    \n",
    "    a, b = linfit.linfit_lonlat(prgather_f_em, \"time\")\n",
    "    prtrend_2006_2099[index,:,:]=b*100.\n",
    "    \n",
    "prtrend_mskd = xr.DataArray(np.array(prtrend_2006_2099)*np.array(mask), coords=prtrend_2006_2099.coords)\n",
    "prtrend_cal = avg.cosweightlonlat(prtrend_mskd, 0, 360, -90, 90)\n",
    "prtrend_cal = prtrend_cal.rename(\"prtrend_cal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "calpvalues = xr.merge([prtrend_cal, cor_nino_calp_p, cor_nino_calp_f])\n",
    "calpvalues.to_netcdf(path=pathout+\"CMIP5calpvalues.nc\")\n",
    "\n",
    "prtrend_2006_2099.to_netcdf(path=pathout+\"CMIP5calpmaptrends.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ecpaperenv]",
   "language": "python",
   "name": "conda-env-ecpaperenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
